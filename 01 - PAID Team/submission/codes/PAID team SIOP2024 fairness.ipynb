{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16TnBqHZPs_N450JNiO4Y4sTGTiou8qyY","timestamp":1711314128067},{"file_id":"1X85mMzuJk-Ue3-ZHxA6tXFrZRD1yD_VD","timestamp":1711308745282},{"file_id":"1VTLchaezYrMkzF1SAdLlcNrUEtvlNlyU","timestamp":1709516516445}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# This is the code for fairness task in SIOP ML competition 2024\n","Author: Zihao Jia zjia2@gmu.edu\n"],"metadata":{"id":"TF06uu1dLyqQ"}},{"cell_type":"markdown","source":["***Note: all the existing outputs in the current file were original outputs we used for submission.***"],"metadata":{"id":"TSXodc-vOPWp"}},{"cell_type":"markdown","source":["## Analysis strategy\n","###Step 1: Using GPT-4 to create a explanation why the first/second policy is more preferred. This is designed to provide a thought process for the GPT model for later classifications.\n","###Step 2: Using a few-shot learning GPT-4 model to classify which policy is more preferred. During few shot learning, instead of only providing the original policies, we are also producing the reasoning process generated from step 1 to help model create a thinking process."],"metadata":{"id":"_F_8R9UqMWPy"}},{"cell_type":"code","source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"O7NuHwHdM6vJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712282991678,"user_tz":240,"elapsed":16202,"user":{"displayName":"Zihao Jia","userId":"02178286752824871106"}},"outputId":"f5118330-8499-4158-d8a3-47c3a19887cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# install pacakges\n","!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pw1Kdtt5c9DU","executionInfo":{"status":"ok","timestamp":1712283002164,"user_tz":240,"elapsed":10489,"user":{"displayName":"Zihao Jia","userId":"02178286752824871106"}},"outputId":"24e62d6c-21d9-4d96-867b-f0f2a5c02d5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.16.2\n"]}]},{"cell_type":"code","source":["# Read the datasets, you may need to change the directory. But the .csv file names should be the same.\n","input_file_path = '/content/drive/MyDrive/2024 SIOP competition/Reproduce/data/fairness_train.csv'\n","eval_file_path = '/content/drive/MyDrive/2024 SIOP competition/Reproduce/data/fairness_val_public.csv'\n","test_file_path = '/content/drive/MyDrive/2024 SIOP competition/Reproduce/data/Copy of fairness_test_public.csv'"],"metadata":{"id":"DHeKg9MctUEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Replace 'your_file.csv' with the name of your CSV file\n","ds_fairness = pd.read_csv(input_file_path)"],"metadata":{"id":"AAaeijdqtkXh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 1: Generate explanations for training set data.\n","We have already saved and uploaded the new file with generated explanations. You are NOT required to run these codes if your purpose is to reproduce the results for competition only."],"metadata":{"id":"olM0NlstBhsJ"}},{"cell_type":"code","source":["# Import API for OpenAI\n","from openai import OpenAI\n","import openai\n","import os\n","\n","client = OpenAI(api_key= 'your api')"],"metadata":{"id":"MDeQ4NLTBhdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we are generating an explanation for why first/second policy is more preferred for each case in training set.\n","# This step has been done with GPT 4\n","# We have also saved the generated reasons so you do not have to replicate this process again.\n","ds_fairness['reason_gpt4'] = None\n","for i in range(len(ds_fairness)):\n","  completion = client.chat.completions.create(\n","  model=\"gpt-4-0125-preview\",\n","  temperature=1,\n","  messages=[{\"role\": \"user\", \"content\": f\"I have two policies.Policy 1:[{ds_fairness.first_option[i]}].Policy 2: [{ds_fairness.second_option[i]}] employees prefer the {ds_fairness.majority_vote[i]} one. What could be the reasons for that? Provide your answer\"}],\n","  )\n","  ds_fairness['reason_gpt4'][i] = completion.choices[0].message.content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-PTj-vsV6R5r","executionInfo":{"status":"ok","timestamp":1711665457244,"user_tz":240,"elapsed":147,"user":{"displayName":"Zihao Jia","userId":"02178286752824871106"}},"outputId":"ff7a835b-bbaf-4629-9cd9-b792b045605b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     The preference for Policy 1 (Conflict Resoluti...\n","1     Employees might prefer the Diversity and Inclu...\n","2     Employees' preference for Policy 2 over Policy...\n","3     Employees might prefer Policy 1 over Policy 2 ...\n","4     Employees might prefer Policy 1 (the formation...\n","5     Employees might prefer Policy 1 over Policy 2 ...\n","6     Employees might prefer Policy 1 (Employee Supp...\n","7     The preference for Policy 1: [Training in conf...\n","8     Employees might prefer Policy 2, which involve...\n","9     Employees might prefer Policy 2 over Policy 1 ...\n","10    Employees might prefer Policy 2 over Policy 1 ...\n","11    There are several reasons why employees might ...\n","12    Employees might prefer Policy 2, which outline...\n","13    Employees might prefer Policy 2, which establi...\n","14    Employees might prefer Policy 2, which encoura...\n","15    Employees' preference for Policy 2, which ackn...\n","16    Employees might prefer Policy 2 over Policy 1 ...\n","17    There could be several reasons why employees m...\n","18    There could be several reasons why employees m...\n","19    Employees might prefer Policy 1 over Policy 2 ...\n","20    Employees might prefer Policy 2, which focuses...\n","21    Employees might prefer Policy 2 (encouraging p...\n","22    Employees might prefer Policy 2 (Employee Supp...\n","23    The preference for Policy 2, the Grievance Res...\n","Name: reason_gpt4, dtype: object"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#ds_fairness.to_csv('/content/drive/MyDrive/2024 SIOP competition/data/fairness_train_reason.csv')"],"metadata":{"id":"MdyAY5-g7VwA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Step 2: generate resutls with the updated training data."],"metadata":{"id":"cmK1YtnOWbZN"}},{"cell_type":"code","source":["# here is the updated training data file with generate explanations.\n","ds_fairness = pd.read_csv('/content/drive/MyDrive/2024 SIOP competition/Reproduce/data/fairness_train_reason.csv')"],"metadata":{"id":"T_PijOzeBlBt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read the test set\n","ds_eval = pd.read_csv(test_file_path)"],"metadata":{"id":"YVt3v2fTPwDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we are aggregating all examples in the training set to serve as few-shot learning examples later.\n","all_prompt = []\n","for i in range(len(ds_fairness)):\n","  conversation = {\"role\": \"user\", \"content\": f\"Here are two organizational policies, which one do you prefer? First policy: [{ds_fairness.first_option[i]}]. Second policy:[{ds_fairness.second_option[i]}]. Tell me 'first' or 'second' at the beginning of your response, then tell me why\"},{\"role\": \"assistant\", \"content\": f\" {ds_fairness.majority_vote[i]}. Because {ds_fairness.reason_gpt4[i]}, so I prefer the {ds_fairness.majority_vote[i]} one.\"}\n","  all_prompt.append(conversation)"],"metadata":{"id":"XQOiEGGI7tP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# iterate within the test set to generate responses.\n","# All examples in the training set will serve as few-shot learning examples\n","# One question is added to the end of few-shot learning examples. And that question follows the loop in our test set.\n","from itertools import chain\n","predict_666 = []\n","for i in range(len(ds_eval)):\n","  question = {\"role\": \"user\", \"content\": f\"Here are two organizational policies, which one do you prefer? First policy:[{ds_eval.first_option[i]}].Second policy: [{ds_eval.second_option[i]}]. Only tell me first or second in this response. DO NOT show your explaination in your response.\"}\n","  all_prompt_flat = list(chain.from_iterable(all_prompt))\n","  all_prompt_flat.append(question)\n","  completion = client.chat.completions.create(\n","    model=\"gpt-4-0125-preview\",\n","    temperature=0.8,\n","    messages=all_prompt_flat,\n","    seed=666\n","  )\n","  predict_666.append(completion.choices[0].message.content)"],"metadata":{"id":"LOmlvnJMB1PN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# here are our predicted results (same results in the final submission)\n","predict_666"],"metadata":{"id":"RQ3FappjDBVF","executionInfo":{"status":"ok","timestamp":1712283461545,"user_tz":240,"elapsed":130,"user":{"displayName":"Zihao Jia","userId":"02178286752824871106"}},"outputId":"bbea607b-6a21-4812-d30b-53da5e749367","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['second',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'first',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'second',\n"," 'first',\n"," 'second',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'second',\n"," 'second',\n"," 'second',\n"," 'first',\n"," 'second',\n"," 'first',\n"," 'first',\n"," 'second']"]},"metadata":{},"execution_count":13}]}]}